{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pathlib import Path\n",
    "data = Path(\"../data\")\n",
    "plot_path = data / \"plots\"\n",
    "studio_path = data / \"studios\"\n",
    "map_path = data / \"graph3_map\"\n",
    "stat_path = map_path / \"stats\"\n",
    "geojson_path = map_path / \"geojson\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133910</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              username country\n",
       "npartitions=1                 \n",
       "0               object  object\n",
       "133910             ...     ...\n",
       "Dask Name: from_pandas, 1 graph layer"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_country = pd.read_csv(map_path / \"user_country.csv\")\n",
    "user_country = dd.from_pandas(user_country[[\"username\", \"country\"]], npartitions=1).persist()\n",
    "user_country"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animes\n",
    "\n",
    "We load the plain Animes database as we don't need studio information for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "animes = pd.read_csv(data / \"AnimeList.csv\")\n",
    "# sort the animes by title (ascending) and write the anime_id and title to a csv file\n",
    "animes = animes.sort_values(by=[\"title\"], ascending=True)\n",
    "animes[[\"anime_id\", \"title\"]].to_csv(data / \"anime_id_title.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=78</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-csv, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               username anime_id my_watched_episodes my_start_date my_finish_date my_score my_status my_rewatching my_rewatching_ep my_last_updated my_tags\n",
       "npartitions=78                                                                                                                                             \n",
       "                 object    int64               int64        object         object    int64     int64       float64            int64           int64  object\n",
       "                    ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "...                 ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "                    ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "                    ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "Dask Name: read-csv, 1 graph layer"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_animes = dd.read_csv(data /\n",
    "    \"UserAnimeList.csv\",\n",
    "    dtype={\n",
    "        \"username\": \"object\",\n",
    "        \"anime_id\": \"int64\",\n",
    "        \"my_watched_episodes\": \"int64\",\n",
    "        \"my_start_date\": \"str\",\n",
    "        \"my_finish_date\": \"str\",\n",
    "        \"my_score\": \"int64\",\n",
    "        \"my_status\": \"int64\",\n",
    "        \"my_rewatching\": \"float64\",\n",
    "        \"my_rewatching_ep\": \"int64\",\n",
    "        \"my_last_updated\": \"int64\",\n",
    "        \"my_tags\": \"object\",\n",
    "    },\n",
    "    usecols=[\n",
    "        \"username\",\n",
    "        \"anime_id\",\n",
    "        \"my_watched_episodes\",\n",
    "        \"my_start_date\",\n",
    "        \"my_finish_date\",\n",
    "        \"my_score\",\n",
    "        \"my_status\",\n",
    "        \"my_rewatching\",\n",
    "        \"my_rewatching_ep\",\n",
    "        \"my_last_updated\",\n",
    "        \"my_tags\",\n",
    "    ],\n",
    ").persist()\n",
    "\n",
    "user_animes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Country-Animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283044, 133794)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_animes[\"username\"].nunique().compute(), user_country[\"username\"].nunique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>country</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=78</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: merge_chunk, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               username country anime_id my_watched_episodes my_start_date my_finish_date my_score my_status my_rewatching my_rewatching_ep my_last_updated my_tags\n",
       "npartitions=78                                                                                                                                                     \n",
       "                 object  object    int64               int64        object         object    int64     int64       float64            int64           int64  object\n",
       "                    ...     ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "...                 ...     ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "                    ...     ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "                    ...     ...      ...                 ...           ...            ...      ...       ...           ...              ...             ...     ...\n",
       "Dask Name: merge_chunk, 1 graph layer"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge user_animes with user_country\n",
    "user_country_animes = user_country.merge(user_animes, on=\"username\", how=\"inner\").persist()\n",
    "print(user_country_animes[\"username\"].nunique().compute())\n",
    "user_country_animes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country/Animes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country-Most popular animes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: sort_values, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              num_ratings\n",
       "npartitions=1            \n",
       "                    int64\n",
       "                      ...\n",
       "Dask Name: sort_values, 1 graph layer"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group country_users_animes by country,country_aff, then for each group add columns \"anime_id\" and \"num_users\" where num_users is the number of users who have watched anime_id\n",
    "country_top_animes = (\n",
    "    user_country_animes.groupby([\"country\", \"anime_id\"])\n",
    "    .agg({\"username\": \"count\"})\n",
    "    .rename(columns={\"username\": \"num_ratings\"})\n",
    "    .sort_values([\"country\", \"num_ratings\"], ascending=[True, False])\n",
    "    .persist()\n",
    ")\n",
    "country_top_animes.to_csv(stat_path / \"country_top_animes.csv\")\n",
    "country_top_animes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country-Most popular animes (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8404/2607912981.py:5: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  .apply(lambda x: x.nlargest(3, \"num_ratings\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/home/julien/Documents/project-2023-vizmoica/data/graph3_map/stats/country_top_animes_3.csv/0.part']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each country, keep only the first 3 anime_ids\n",
    "country_top_animes_3 = (\n",
    "    country_top_animes.reset_index()\n",
    "    .groupby([\"country\"])\n",
    "    .apply(lambda x: x.nlargest(3, \"num_ratings\"))\n",
    ")\n",
    "country_top_animes_3.to_csv(stat_path / \"country_top_animes_3.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country/Studios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anime-Studios\n",
    "\n",
    "We load the cleaned dataset, which duplicates the rows of animes that have multiple studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_studios = dd.read_csv(data / \"AnimeList_clean.csv\").persist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User-Country-Animes-Studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130417\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>country</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>studio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=78</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: merge_chunk, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               username country anime_id  studio\n",
       "npartitions=78                                  \n",
       "                 object  object    int64  object\n",
       "                    ...     ...      ...     ...\n",
       "...                 ...     ...      ...     ...\n",
       "                    ...     ...      ...     ...\n",
       "                    ...     ...      ...     ...\n",
       "Dask Name: merge_chunk, 1 graph layer"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_country_animes_studios = (\n",
    "    user_country_animes[[\"username\", \"country\", \"anime_id\"]]\n",
    "    .merge(anime_studios[[\"anime_id\", \"studio\"]], on=\"anime_id\", how=\"inner\")\n",
    "    .persist()\n",
    ")\n",
    "print(user_country_animes_studios[\"username\"].nunique().compute())\n",
    "user_country_animes_studios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studio-Country-Number of ratings for that studio in that country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [Errno 2] No such file or directory: '/home/julien/Documents/project-2023-vizmoica/preprocessing/../data/graph3_map/stats/studio_country_num_ratings.csv/0.part'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/backends.py:135\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/io/csv.py:755\u001b[0m, in \u001b[0;36mmake_reader.<locals>.read\u001b[0;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\n\u001b[1;32m    743\u001b[0m     urlpath,\n\u001b[1;32m    744\u001b[0m     blocksize\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    754\u001b[0m ):\n\u001b[0;32m--> 755\u001b[0m     \u001b[39mreturn\u001b[39;00m read_pandas(\n\u001b[1;32m    756\u001b[0m         reader,\n\u001b[1;32m    757\u001b[0m         urlpath,\n\u001b[1;32m    758\u001b[0m         blocksize\u001b[39m=\u001b[39;49mblocksize,\n\u001b[1;32m    759\u001b[0m         lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m    760\u001b[0m         compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    761\u001b[0m         sample\u001b[39m=\u001b[39;49msample,\n\u001b[1;32m    762\u001b[0m         sample_rows\u001b[39m=\u001b[39;49msample_rows,\n\u001b[1;32m    763\u001b[0m         enforce\u001b[39m=\u001b[39;49menforce,\n\u001b[1;32m    764\u001b[0m         assume_missing\u001b[39m=\u001b[39;49massume_missing,\n\u001b[1;32m    765\u001b[0m         storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    766\u001b[0m         include_path_column\u001b[39m=\u001b[39;49minclude_path_column,\n\u001b[1;32m    767\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    768\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/dataframe/io/csv.py:559\u001b[0m, in \u001b[0;36mread_pandas\u001b[0;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m b_lineterminator \u001b[39m=\u001b[39m lineterminator\u001b[39m.\u001b[39mencode()\n\u001b[0;32m--> 559\u001b[0m b_out \u001b[39m=\u001b[39m read_bytes(\n\u001b[1;32m    560\u001b[0m     urlpath,\n\u001b[1;32m    561\u001b[0m     delimiter\u001b[39m=\u001b[39;49mb_lineterminator,\n\u001b[1;32m    562\u001b[0m     blocksize\u001b[39m=\u001b[39;49mblocksize,\n\u001b[1;32m    563\u001b[0m     sample\u001b[39m=\u001b[39;49msample,\n\u001b[1;32m    564\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    565\u001b[0m     include_path\u001b[39m=\u001b[39;49minclude_path_column,\n\u001b[1;32m    566\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(storage_options \u001b[39mor\u001b[39;49;00m {}),\n\u001b[1;32m    567\u001b[0m )\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m include_path_column:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/bytes/core.py:109\u001b[0m, in \u001b[0;36mread_bytes\u001b[0;34m(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot do chunked reads on compressed files. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo read, set blocksize=None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m     )\n\u001b[0;32m--> 109\u001b[0m size \u001b[39m=\u001b[39m fs\u001b[39m.\u001b[39;49minfo(path)[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    110\u001b[0m \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/fsspec/implementations/local.py:87\u001b[0m, in \u001b[0;36mLocalFileSystem.info\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strip_protocol(path)\n\u001b[0;32m---> 87\u001b[0m out \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(path, follow_symlinks\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     88\u001b[0m link \u001b[39m=\u001b[39m stat\u001b[39m.\u001b[39mS_ISLNK(out\u001b[39m.\u001b[39mst_mode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/julien/Documents/project-2023-vizmoica/preprocessing/../data/graph3_map/stats/studio_country_num_ratings.csv/0.part'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/julien/Documents/project-2023-vizmoica/preprocessing/eda_country_stats_2.ipynb Cell 27\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/julien/Documents/project-2023-vizmoica/preprocessing/eda_country_stats_2.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m studio_country_num_ratings \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39;49mread_csv(stat_path \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mstudio_country_num_ratings.csv/0.part\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mpersist()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/julien/Documents/project-2023-vizmoica/preprocessing/eda_country_stats_2.ipynb#X35sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m studio_country_num_ratings\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/dask/backends.py:137\u001b[0m, in \u001b[0;36mCreationDispatch.register_inplace.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mtype\u001b[39m(e)(\n\u001b[1;32m    138\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling the \u001b[39m\u001b[39m{\u001b[39;00mfuncname(func)\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmethod registered to the \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackend\u001b[39m}\u001b[39;00m\u001b[39m backend.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOriginal Message: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: An error occurred while calling the read_csv method registered to the pandas backend.\nOriginal Message: [Errno 2] No such file or directory: '/home/julien/Documents/project-2023-vizmoica/preprocessing/../data/graph3_map/stats/studio_country_num_ratings.csv/0.part'"
     ]
    }
   ],
   "source": [
    "studio_country_num_ratings = dd.read_csv(stat_path / \"studio_country_num_ratings.csv/0.part\").persist()\n",
    "studio_country_num_ratings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studio-Country-Most popular animes (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13490/2418989499.py:8: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  .apply(lambda x: x.nlargest(3, \"num_ratings\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studio</th>\n",
       "      <th>country</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: lambda, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               studio country anime_id num_ratings\n",
       "npartitions=1                                     \n",
       "               object  object    int64       int64\n",
       "                  ...     ...      ...         ...\n",
       "Dask Name: lambda, 1 graph layer"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "studio_country_top_animes_3 = (\n",
    "    user_country_animes_studios.groupby([\"studio\", \"country\", \"anime_id\"])\n",
    "    .agg({\"username\": \"count\"})\n",
    "    .rename(columns={\"username\": \"num_ratings\"})\n",
    "    .sort_values([\"studio\", \"country\", \"num_ratings\"], ascending=[True, True, False])\n",
    "    .reset_index()\n",
    "    .groupby([\"studio\", \"country\"])\n",
    "    .apply(lambda x: x.nlargest(3, \"num_ratings\"))\n",
    "    # .reset_index(drop=True)\n",
    "    .persist()\n",
    ")\n",
    "\n",
    "studio_country_top_animes_3.to_csv(stat_path / \"studio_country_top_animes_3.csv\")\n",
    "studio_country_top_animes_3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country-Most popular studios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: sort_values, 1 graph layer</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              num_ratings\n",
       "npartitions=1            \n",
       "                    int64\n",
       "                      ...\n",
       "Dask Name: sort_values, 1 graph layer"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_top_studios = (\n",
    "    user_country_animes_studios.groupby([\"country\", \"studio\"])\n",
    "    .agg({\"username\": \"count\"})\n",
    "    .rename(columns={\"username\": \"num_ratings\"})\n",
    "    .sort_values([\"country\", \"num_ratings\", \"studio\"], ascending=[True, False, True])\n",
    "    .persist()\n",
    ")\n",
    "country_top_studios.to_csv(stat_path / \"country_top_studios.csv\")\n",
    "country_top_studios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country/Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>country</th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_watched_episodes</th>\n",
       "      <th>my_start_date</th>\n",
       "      <th>my_finish_date</th>\n",
       "      <th>my_score</th>\n",
       "      <th>my_status</th>\n",
       "      <th>my_rewatching</th>\n",
       "      <th>my_rewatching_ep</th>\n",
       "      <th>my_last_updated</th>\n",
       "      <th>my_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>434285</th>\n",
       "      <td>Elyasis</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>20</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1445193740</td>\n",
       "      <td>Mystery, Police, Psychological, Supernatural, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449029</th>\n",
       "      <td>Sinope_K</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>11</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1459627501</td>\n",
       "      <td>(&lt;2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451467</th>\n",
       "      <td>Myou-Myou</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>2011-06-30</td>\n",
       "      <td>2011-07-03</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1317745450</td>\n",
       "      <td>last arc is meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454601</th>\n",
       "      <td>Mayuri-Nyan</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1328812789</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455122</th>\n",
       "      <td>Yamichan</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1437060882</td>\n",
       "      <td>Psychological, Supernatural, Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337641</th>\n",
       "      <td>Levitacus</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1477449618</td>\n",
       "      <td>Mid 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331882</th>\n",
       "      <td>EternalPhoenix</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1325506271</td>\n",
       "      <td>15.5/20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333213</th>\n",
       "      <td>KloWh</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1379520124</td>\n",
       "      <td>Stop after the 1 st arc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335689</th>\n",
       "      <td>Anjolras</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1357126510</td>\n",
       "      <td>Thrilling story with suspens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338132</th>\n",
       "      <td>Steinstwo</td>\n",
       "      <td>France</td>\n",
       "      <td>1535</td>\n",
       "      <td>37</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>0000-00-00</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1412710908</td>\n",
       "      <td>Mystery, Supernatural, Police, Psychological, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              username country  anime_id  my_watched_episodes my_start_date  \\\n",
       "434285         Elyasis  France      1535                   20    0000-00-00   \n",
       "449029        Sinope_K  France      1535                   11    2015-11-01   \n",
       "451467       Myou-Myou  France      1535                   37    2011-06-30   \n",
       "454601     Mayuri-Nyan  France      1535                   37    0000-00-00   \n",
       "455122        Yamichan  France      1535                   37    0000-00-00   \n",
       "...                ...     ...       ...                  ...           ...   \n",
       "337641       Levitacus  France      1535                   37    0000-00-00   \n",
       "331882  EternalPhoenix  France      1535                   37    0000-00-00   \n",
       "333213           KloWh  France      1535                   37    0000-00-00   \n",
       "335689        Anjolras  France      1535                   37    0000-00-00   \n",
       "338132       Steinstwo  France      1535                   37    0000-00-00   \n",
       "\n",
       "       my_finish_date  my_score  my_status  my_rewatching  my_rewatching_ep  \\\n",
       "434285     0000-00-00         7          4            NaN                 0   \n",
       "449029     0000-00-00         0          1            0.0                 0   \n",
       "451467     2011-07-03         8          2            0.0                 0   \n",
       "454601     0000-00-00        10          2            NaN                 0   \n",
       "455122     0000-00-00         8          2            0.0                 0   \n",
       "...               ...       ...        ...            ...               ...   \n",
       "337641     0000-00-00         7          2            0.0                 0   \n",
       "331882     0000-00-00         7          2            0.0                 0   \n",
       "333213     0000-00-00         7          2            NaN                 0   \n",
       "335689     0000-00-00        10          2            0.0                 0   \n",
       "338132     0000-00-00         7          2            NaN                 0   \n",
       "\n",
       "        my_last_updated                                            my_tags  \n",
       "434285       1445193740  Mystery, Police, Psychological, Supernatural, ...  \n",
       "449029       1459627501                                            (<2009)  \n",
       "451467       1317745450                                    last arc is meh  \n",
       "454601       1328812789                                                 10  \n",
       "455122       1437060882              Psychological, Supernatural, Thriller  \n",
       "...                 ...                                                ...  \n",
       "337641       1477449618                                              Mid 7  \n",
       "331882       1325506271                                            15.5/20  \n",
       "333213       1379520124                            Stop after the 1 st arc  \n",
       "335689       1357126510                       Thrilling story with suspens  \n",
       "338132       1412710908  Mystery, Supernatural, Police, Psychological, ...  \n",
       "\n",
       "[222 rows x 12 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_country_animes[\n",
    "    (user_country_animes[\"country\"] == \"France\") & \n",
    "    (user_country_animes[\"anime_id\"] == 1535) & \n",
    "    (user_country_animes[\"my_tags\"].notnull())\n",
    "].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316539    Esse anime no começo não botei muita fé,mas qu...\n",
       "317872    se não fosse essa parte final broxante, eu ter...\n",
       "318110                                         L DEAD YEAH!\n",
       "320316                                     shounen, mystery\n",
       "335467    Até é bem inteligente, mas o anime perde a gra...\n",
       "                                ...                        \n",
       "267909    Mystery, Supernatural, Police, Psychological, ...\n",
       "269784    Uma das primeiras obras que eu assisti, me apa...\n",
       "273418    Muito bom! Premissa genial, com uma execução f...\n",
       "261377                                           Perfeição.\n",
       "267146                        Kira &gt; L. (não me julguem)\n",
       "Name: my_tags, Length: 712, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_country_animes[\n",
    "    (user_country_animes[\"country\"] == \"Brazil\") & \n",
    "    (user_country_animes[\"anime_id\"] == 1535) & \n",
    "    (user_country_animes[\"my_tags\"].notnull())\n",
    "][\"my_tags\"].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "359279                       death note,death god,shinigami\n",
       "350170    Mystery, Psychological thriller, Supernatural ...\n",
       "347334                                           =|ED&PS|x1\n",
       "347703                                           Death Note\n",
       "287889                   legend of the galactic heroes lite\n",
       "Name: my_tags, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_country_animes[\n",
    "    (user_country_animes[\"country\"] == \"Iran\") & \n",
    "    (user_country_animes[\"anime_id\"] == 1535) & \n",
    "    (user_country_animes[\"my_tags\"].notnull())\n",
    "][\"my_tags\"].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
